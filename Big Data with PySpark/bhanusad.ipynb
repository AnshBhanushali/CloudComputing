{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebfdf434-dbab-4bff-a5ef-933689bb6806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Big Data With PySpark/2015/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2015/99495199999.csv -> row count: 355\n",
      "Loaded Big Data With PySpark/2016/72429793812.csv -> row count: 366\n",
      "File NOT found: Big Data With PySpark/2016/99495199999.csv\n",
      "Loaded Big Data With PySpark/2017/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2017/99495199999.csv -> row count: 283\n",
      "Loaded Big Data With PySpark/2018/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2018/99495199999.csv -> row count: 363\n",
      "Loaded Big Data With PySpark/2019/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2019/99495199999.csv -> row count: 345\n",
      "Loaded Big Data With PySpark/2020/72429793812.csv -> row count: 366\n",
      "Loaded Big Data With PySpark/2020/99495199999.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2021/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2021/99495199999.csv -> row count: 104\n",
      "Loaded Big Data With PySpark/2022/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2022/99495199999.csv -> row count: 259\n",
      "Loaded Big Data With PySpark/2023/72429793812.csv -> row count: 365\n",
      "Loaded Big Data With PySpark/2023/99495199999.csv -> row count: 276\n",
      "Loaded Big Data With PySpark/2024/72429793812.csv -> row count: 366\n",
      "Loaded Big Data With PySpark/2024/99495199999.csv -> row count: 133\n",
      "\n",
      "Unified DataFrame Schema:\n",
      "root\n",
      " |-- STATION: long (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      " |-- YEAR: integer (nullable = false)\n",
      " |-- STATION_ID: string (nullable = false)\n",
      "\n",
      "\n",
      "Showing a few rows from the combined DataFrame:\n",
      "+-----------+----------+--------+---------+---------+--------------------+----+---------------+----+---------------+------+--------------+-----+--------------+-----+----------------+----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+----+-----------+\n",
      "|    STATION|      DATE|LATITUDE|LONGITUDE|ELEVATION|                NAME|TEMP|TEMP_ATTRIBUTES|DEWP|DEWP_ATTRIBUTES|   SLP|SLP_ATTRIBUTES|  STP|STP_ATTRIBUTES|VISIB|VISIB_ATTRIBUTES|WDSP|WDSP_ATTRIBUTES|MXSPD| GUST| MAX|MAX_ATTRIBUTES| MIN|MIN_ATTRIBUTES|PRCP|PRCP_ATTRIBUTES| SNDP|FRSHTT|YEAR| STATION_ID|\n",
      "+-----------+----------+--------+---------+---------+--------------------+----+---------------+----+---------------+------+--------------+-----+--------------+-----+----------------+----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+----+-----------+\n",
      "|72429793812|2015-01-01|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|26.1|           24.0|10.9|           24.0|1025.5|          24.0|  6.8|          24.0| 10.0|            24.0|10.0|           24.0| 18.1| 22.9|39.0|              |15.1|              | 0.0|              G|999.9|     0|2015|72429793812|\n",
      "|72429793812|2015-01-02|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|33.3|           24.0|25.3|           24.0|1026.4|          22.0|  7.9|          24.0| 10.0|            24.0| 4.1|           24.0|  8.9|999.9|39.0|              |18.0|              | 0.0|              G|999.9|     0|2015|72429793812|\n",
      "|72429793812|2015-01-03|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|41.8|           24.0|39.9|           24.0|1020.4|          13.0|  0.7|          24.0|  6.1|            24.0| 3.5|           24.0| 15.9| 25.1|61.0|              |26.1|              |0.42|              G|999.9| 10010|2015|72429793812|\n",
      "|72429793812|2015-01-04|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|50.0|           24.0|45.9|           24.0|1013.2|          16.0|994.2|          24.0|  9.7|            24.0|12.9|           24.0| 18.1| 28.9|61.0|              |35.1|              |0.61|              G|999.9| 10000|2015|72429793812|\n",
      "|72429793812|2015-01-05|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|20.2|           24.0| 8.9|           24.0|1034.9|          22.0| 16.0|          24.0|  9.9|            24.0|11.0|           24.0| 19.0| 27.0|33.1|             *|14.0|             *|0.04|              G|999.9|  1000|2015|72429793812|\n",
      "+-----------+----------+--------+---------+---------+--------------------+----+---------------+----+---------------+------+--------------+-----+--------------+-----+----------------+----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "#  LOAD WEATHER CSVs     #\n",
    "##########################\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.appName(\"WeatherAnalysis\").getOrCreate()\n",
    "\n",
    "base_path = \"Big Data With PySpark\"   \n",
    "\n",
    "\n",
    "years = range(2015, 2025)\n",
    "stations = [\"72429793812\", \"99495199999\"]  \n",
    "df_list = []  \n",
    "\n",
    "for y in years:\n",
    "    for stn in stations:\n",
    "        csv_path = os.path.join(base_path, str(y), f\"{stn}.csv\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            # Read the CSV\n",
    "            df_temp = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "            row_count = df_temp.count()\n",
    "            print(f\"Loaded {csv_path} -> row count: {row_count}\")\n",
    "            from pyspark.sql.functions import lit\n",
    "            df_temp = df_temp.withColumn(\"YEAR\", lit(y)) \\\n",
    "                             .withColumn(\"STATION_ID\", lit(stn))\n",
    "            \n",
    "            df_list.append(df_temp)\n",
    "        else:\n",
    "            # If file not found, just note it\n",
    "            print(f\"File NOT found: {csv_path}\")\n",
    "\n",
    "if df_list:\n",
    "    from functools import reduce\n",
    "    from pyspark.sql import DataFrame\n",
    "    weather_df = reduce(lambda a, b: a.union(b), df_list)\n",
    "    \n",
    "    print(\"\\nUnified DataFrame Schema:\")\n",
    "    weather_df.printSchema()\n",
    "    \n",
    "    print(\"\\nShowing a few rows from the combined DataFrame:\")\n",
    "    weather_df.show(5)\n",
    "else:\n",
    "    print(\"No CSVs loaded at all. Please check your folder structure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaed235b-7bce-4e47-aad6-8593867f0640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------------------------------------+----------+------+\n",
      "|YEAR|STATION_ID |NAME                                            |DATE      |MAX   |\n",
      "+----+-----------+------------------------------------------------+----------+------+\n",
      "|2015|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2015-06-12|91.9  |\n",
      "|2016|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2016-07-24|93.9  |\n",
      "|2017|99495199999|SEBASTIAN INLET STATE PARK, FL US               |2017-02-22|9999.9|\n",
      "|2018|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2018-07-04|96.1  |\n",
      "|2019|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2019-09-30|95.0  |\n",
      "|2020|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2020-07-05|93.9  |\n",
      "|2021|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2021-08-12|95.0  |\n",
      "|2022|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2022-12-23|9999.9|\n",
      "|2023|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2023-08-23|96.1  |\n",
      "|2024|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2024-08-30|100.9 |\n",
      "+----+-----------+------------------------------------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, desc\n",
    "\n",
    "window_year = Window.partitionBy(\"YEAR\").orderBy(desc(\"MAX\"))\n",
    "hottest_df = weather_df.withColumn(\"rn\", row_number().over(window_year)) \\\n",
    "                       .filter(\"rn = 1\") \\\n",
    "                       .select(\"YEAR\", \"STATION_ID\", \"NAME\", \"DATE\", \"MAX\")\n",
    "hottest_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f3c1b0-df36-4c22-a551-87c21b340b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------------------+----------+---+\n",
      "|STATION_ID |NAME                                            |DATE      |MIN|\n",
      "+-----------+------------------------------------------------+----------+---+\n",
      "|72429793812|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2015-03-06|3.2|\n",
      "+-----------+------------------------------------------------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month\n",
    "\n",
    "march_df = weather_df.filter(month(weather_df.DATE) == 3)\n",
    "\n",
    "coldest_march = (\n",
    "    march_df\n",
    "    .orderBy(\"MIN\")\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "coldest_march.select(\"STATION_ID\", \"NAME\", \"DATE\", \"MIN\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599a2f62-5dd9-4d34-ac50-79e242aa9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----------------+\n",
      "|STATION_ID |YEAR|mean_prcp        |\n",
      "+-----------+----+-----------------+\n",
      "|72429793812|2024|4.503497267759559|\n",
      "|99495199999|2015|0.0              |\n",
      "+-----------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, row_number\n",
    "\n",
    "prcp_df = weather_df.groupBy(\"STATION_ID\", \"YEAR\").agg(avg(\"PRCP\").alias(\"mean_prcp\"))\n",
    "\n",
    "window_station = Window.partitionBy(\"STATION_ID\").orderBy(desc(\"mean_prcp\"))\n",
    "\n",
    "prcp_ranked = prcp_df.withColumn(\"rn\", row_number().over(window_station))\n",
    "top_prcp = prcp_ranked.filter(\"rn = 1\").select(\"STATION_ID\", \"YEAR\", \"mean_prcp\")\n",
    "\n",
    "top_prcp.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "114b7574-d477-4d6c-b036-20c705cada61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|STATION_ID |pct_missing_gust |\n",
      "+-----------+-----------------+\n",
      "|72429793812|39.07103825136612|\n",
      "|99495199999|100.0            |\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, sum as spark_sum, count, col\n",
    "\n",
    "df_2024 = weather_df.filter(col(\"YEAR\") == 2024)\n",
    "\n",
    "missing_cond = (col(\"GUST\").isNull()) | (col(\"GUST\") == 999.9) | (col(\"GUST\") == 9999.9)\n",
    "\n",
    "gust_missing = (\n",
    "    df_2024\n",
    "    .groupBy(\"STATION_ID\")\n",
    "    .agg(\n",
    "        (spark_sum(when(missing_cond, 1).otherwise(0)) / count(\"*\") * 100).alias(\"pct_missing_gust\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gust_missing.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207852e3-5702-4afa-a5b5-3c11529cff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-----------+-----------------+---------+\n",
      "|MONTH|mean_temp         |median_temp|stddev_temp      |mode_temp|\n",
      "+-----+------------------+-----------+-----------------+---------+\n",
      "|1    |37.94516129032259 |37.7       |8.345810873712928|24.7     |\n",
      "|2    |36.5896551724138  |36.0       |7.90159770587055 |25.9     |\n",
      "|3    |49.0741935483871  |47.8       |8.779406500135623|43.0     |\n",
      "|4    |51.779999999999994|51.0       |7.313162436838541|55.7     |\n",
      "|5    |60.89032258064518 |63.7       |9.314768017820217|73.9     |\n",
      "|6    |72.54666666666667 |73.7       |4.899946047087439|74.7     |\n",
      "|7    |77.6              |77.9       |2.33794781806609 |77.5     |\n",
      "|8    |73.34516129032258 |73.7       |3.487868375734898|73.2     |\n",
      "|9    |66.1              |65.8       |7.118262089331474|75.3     |\n",
      "|10   |55.193548387096776|54.0       |6.72869157582517 |63.8     |\n",
      "|11   |48.003333333333345|47.7       |6.825938527529321|47.7     |\n",
      "|12   |35.99354838709677 |35.2       |6.642787340861814|32.1     |\n",
      "+-----+------------------+-----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, mean as spark_mean, stddev as spark_stddev\n",
    "from pyspark.sql.functions import percentile_approx\n",
    "\n",
    "# 1) Filter data\n",
    "cincy_2020 = weather_df.filter(\n",
    "    (col(\"STATION_ID\") == \"72429793812\") &\n",
    "    (col(\"YEAR\") == 2020)\n",
    ")\n",
    "\n",
    "# 2) Create a MONTH column\n",
    "cincy_2020 = cincy_2020.withColumn(\"MONTH\", month(cincy_2020.DATE))\n",
    "\n",
    "# 3) Calculate mean, median, stddev\n",
    "stats_df = cincy_2020.groupBy(\"MONTH\").agg(\n",
    "    spark_mean(\"TEMP\").alias(\"mean_temp\"),\n",
    "    percentile_approx(\"TEMP\", 0.5).alias(\"median_temp\"),\n",
    "    spark_stddev(\"TEMP\").alias(\"stddev_temp\")\n",
    ")\n",
    "\n",
    "# 4) Calculate mode\n",
    "#    Count how often each TEMP occurs in each month\n",
    "temp_count = cincy_2020.groupBy(\"MONTH\", \"TEMP\").count()\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "window_mode = Window.partitionBy(\"MONTH\").orderBy(desc(\"count\"))\n",
    "\n",
    "mode_df = (\n",
    "    temp_count\n",
    "    .withColumn(\"rn\", row_number().over(window_mode))\n",
    "    .filter(\"rn = 1\")\n",
    "    .select(col(\"MONTH\").alias(\"MODE_MONTH\"), col(\"TEMP\").alias(\"mode_temp\"))\n",
    ")\n",
    "\n",
    "# 5) Join the mode back to the stats\n",
    "final_stats = (\n",
    "    stats_df\n",
    "    .join(mode_df, stats_df.MONTH == mode_df.MODE_MONTH, \"left\")\n",
    "    .drop(\"MODE_MONTH\")\n",
    "    .orderBy(\"MONTH\")\n",
    ")\n",
    "\n",
    "final_stats.show(12, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ed3643-93c8-4c9d-a0ac-05d772771cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+-------------------+\n",
      "|DATE      |TEMP|WDSP|WIND_CHILL         |\n",
      "+----------+----+----+-------------------+\n",
      "|2017-01-07|10.5|7.0 |-0.4140156367932173|\n",
      "|2017-12-31|11.0|5.3 |2.0339767075993116 |\n",
      "|2017-12-27|13.0|5.8 |3.820645509123832  |\n",
      "|2017-12-28|13.6|5.8 |4.533355269061226  |\n",
      "|2017-01-06|13.6|5.5 |4.868933041653884  |\n",
      "|2017-01-08|15.9|5.2 |7.929748208036862  |\n",
      "|2017-12-25|25.8|13.5|14.285113218297408 |\n",
      "|2017-12-30|21.6|5.3 |14.539211253038193 |\n",
      "|2017-01-05|22.2|5.8 |14.748861828163854 |\n",
      "|2017-12-26|23.3|6.2 |15.688977805634499 |\n",
      "+----------+----+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pow, asc\n",
    "\n",
    "df_cincy_2017 = weather_df.filter(\n",
    "    (col(\"STATION_ID\") == \"72429793812\") &\n",
    "    (col(\"YEAR\") == 2017) &\n",
    "    (col(\"TEMP\") < 50) &\n",
    "    (col(\"WDSP\") > 3)\n",
    ")\n",
    "\n",
    "df_cincy_2017 = df_cincy_2017.withColumn(\n",
    "    \"WIND_CHILL\",\n",
    "    35.74 + 0.6215*col(\"TEMP\")\n",
    "    - 35.75*pow(col(\"WDSP\"), 0.16)\n",
    "    + 0.4275*col(\"TEMP\")*pow(col(\"WDSP\"), 0.16)\n",
    ")\n",
    "\n",
    "lowest_wc = df_cincy_2017.orderBy(asc(\"WIND_CHILL\")).limit(10)\n",
    "\n",
    "lowest_wc.select(\"DATE\", \"TEMP\", \"WDSP\", \"WIND_CHILL\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88861426-fb4a-4e91-8f24-0c1224f8f51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days with extreme weather in Florida: 0\n"
     ]
    }
   ],
   "source": [
    "df_fl = weather_df.filter(col(\"STATION_ID\") == \"99495199999\")\n",
    "\n",
    "extreme_count = df_fl.filter(col(\"FRSHTT\") != 0).count()\n",
    "\n",
    "print(\"Number of days with extreme weather in Florida:\", extreme_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c470c3c-82c9-414b-8240-70d92482d755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/23 19:06:51 WARN Instrumentation: [28a8ae06] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.24552368695755147]\n",
      "Intercept: 38.237247478548916\n",
      "Training RMSE: 366.7695009694051\n",
      "+-----+------------------+\n",
      "|MONTH|      PredictedMax|\n",
      "+-----+------------------+\n",
      "|   11|120.48768260932866|\n",
      "|   12|128.09891690501274|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "import datetime\n",
    "\n",
    "def day_of_year_func(d):\n",
    "    if d is None:\n",
    "        return None\n",
    "    return d.timetuple().tm_yday\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "day_of_year_udf = udf(day_of_year_func, IntegerType())\n",
    "\n",
    "# 1) Training data (Cincinnati, 2022–2023)\n",
    "train_df = weather_df.filter(\n",
    "    (col(\"STATION_ID\") == \"72429793812\") &\n",
    "    (col(\"YEAR\").isin([2022, 2023]))\n",
    ").select(\"DATE\", \"MAX\")\n",
    "\n",
    "train_df = train_df.withColumn(\"day_of_year\", day_of_year_udf(col(\"DATE\")))\n",
    "train_df = train_df.dropna(subset=[\"day_of_year\", \"MAX\"])\n",
    "\n",
    "# 2) Spark ML setup\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"day_of_year\"], outputCol=\"features\")\n",
    "train_model_df = assembler.transform(train_df).select(\"features\", col(\"MAX\").alias(\"label\"))\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_model_df)\n",
    "\n",
    "print(\"Coefficients:\", lr_model.coefficients)\n",
    "print(\"Intercept:\", lr_model.intercept)\n",
    "print(\"Training RMSE:\", lr_model.summary.rootMeanSquaredError)\n",
    "\n",
    "# 3) Predict for 2024 (Nov/Dec)\n",
    "predict_2024 = weather_df.filter(\n",
    "    (col(\"STATION_ID\") == \"72429793812\") &\n",
    "    (col(\"YEAR\") == 2024)\n",
    "    & (month(col(\"DATE\")).isin([11, 12]))\n",
    ").select(\"DATE\", \"MAX\")\n",
    "\n",
    "predict_2024 = predict_2024.withColumn(\"day_of_year\", day_of_year_udf(col(\"DATE\")))\n",
    "predict_2024_df = assembler.transform(predict_2024).select(\"DATE\", \"MAX\", \"features\")\n",
    "\n",
    "predictions = lr_model.transform(predict_2024_df)\n",
    "\n",
    "from pyspark.sql.functions import month, max as spark_max\n",
    "\n",
    "# If you just want a single predicted max for each month\n",
    "pred_month = (\n",
    "    predictions\n",
    "    .withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "    .groupBy(\"MONTH\")\n",
    "    .agg(spark_max(\"prediction\").alias(\"PredictedMax\"))\n",
    "    .orderBy(\"MONTH\")\n",
    ")\n",
    "\n",
    "pred_month.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36868318-f2ba-436c-b244-13eca6ed359b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
